{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to make a FCN to predict dihedral angles. The data is from https://github.com/aqlaboratory/proteinnet casp7, text based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import imp\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_id_dict = {'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4, 'G': 5, 'H': 6, 'I': 7,\n",
    "              'K': 8, 'L': 9, 'M': 10, 'N': 11, 'P': 12, 'Q': 13, 'R': 14, \n",
    "              'S': 15, 'T': 16, 'V': 17, 'W': 18, 'Y': 19}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First define some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aa_to_onehot(aa_str, aa_to_nr, mask=None):\n",
    "    \"\"\"\n",
    "    Onehot encode an amino acid string using a letter to number dictionary.\n",
    "    The mask (from proteinnet files) is used to remove residues missing atoms from the primary sequence.\n",
    "    \"\"\"\n",
    "    if mask!=None:\n",
    "        mask_ind = np.asarray([x=='+' for x in mask])*1\n",
    "        mask_ind = np.nonzero(mask_ind)\n",
    "        aa_str = \"\".join([aa_str[x] for x in mask_ind[0]]) # the mask indices are a list in a list\n",
    "    init_array = np.zeros( (len(aa_to_nr.keys()), len(aa_str)) )\n",
    "    for i,j in enumerate(aa_str):\n",
    "        init_array[aa_to_nr[j], i] = 1\n",
    "    return(init_array)\n",
    "\n",
    "def filter_primary(aa_str, mask):\n",
    "    '''\n",
    "    Need this later on for writing pdb files, but should probably just use it at the start...\n",
    "    '''\n",
    "    mask_ind = np.asarray([x=='+' for x in mask])*1\n",
    "    mask_ind = np.nonzero(mask_ind)\n",
    "    aa_str = \"\".join([aa_str[x] for x in mask_ind[0]]) # the mask indices are a list in a list\n",
    "    return(aa_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_proteinnet_file(file, stop_at=1000, verbose=True):\n",
    "    \"\"\"\n",
    "    Read a proteinnet file. Will also filter the 3D coordinates using the mask\n",
    "    and remove proteins with chainbreaks and missing structures. \n",
    "    A certain number of proteins are loaded.\n",
    "    \"\"\"\n",
    "    protein_dict = {}\n",
    "    with open(file) as input:\n",
    "        lines = input.readlines()\n",
    "        curr_id = None\n",
    "        for i, line in enumerate(lines):\n",
    "            line = line.strip()\n",
    "            if line == '[ID]':\n",
    "                curr_id = lines[i+1].strip()\n",
    "                protein_dict[curr_id] = {}\n",
    "                protein_dict[curr_id]['primary'] = lines[i+3].strip()\n",
    "            if line == '[TERTIARY]':\n",
    "                coords = []\n",
    "                for j in range(3):\n",
    "                    coords.append(np.fromstring(lines[i+j+1], sep='\\t'))\n",
    "                protein_dict[curr_id]['tertiary'] = np.array(coords)\n",
    "            if line == '[MASK]':\n",
    "                protein_dict[curr_id]['mask'] = lines[i+1].strip()\n",
    "            if len(protein_dict.keys()) >= stop_at:\n",
    "                break\n",
    "    filter_seqs(protein_dict, verbose)\n",
    "    return(protein_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the proteinnet documentation the protein coordinates should be stored as a sequence of 3x3 arrays corresponding to the coordinates of N, CA and C for each residue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_coords(coords, mask):\n",
    "    \"\"\"\n",
    "    Filter atomic coordinates (for residues missing some) using the mask.\n",
    "    coords = 3*(N*3) array, since each residue has N, CA and C\n",
    "    \"\"\"\n",
    "    mask = np.array([x=='+' for x in mask])\n",
    "    mask_stretched = np.repeat(mask, 3)\n",
    "    coords_filt = coords[:, mask_stretched]\n",
    "    return(coords_filt)\n",
    "\n",
    "def filter_seqs(protein_dict, verbose):\n",
    "    re_chainbreak = re.compile(\"\\-*\\+*\\+\\-+\\+\\+*\\-*\") # match for a mask with internal chainbreaks\n",
    "    keys_to_remove = {}\n",
    "    for key in protein_dict.keys():\n",
    "        if len(protein_dict[key].keys()) < 3:\n",
    "            keys_to_remove[key] = ' missing structure, removing...'\n",
    "            continue\n",
    "        mask = protein_dict[key]['mask']\n",
    "        if re_chainbreak.search(mask):\n",
    "            keys_to_remove[key] = \" has a chainbreak, removing...\"\n",
    "        else:\n",
    "            coords = protein_dict[key]['tertiary']\n",
    "            coords_filt = filter_coords(coords, mask)\n",
    "            protein_dict[key]['tertiary'] = coords_filt\n",
    "    for key in keys_to_remove.keys():\n",
    "        if verbose:\n",
    "            print(key, keys_to_remove[key])\n",
    "        del protein_dict[key]\n",
    "\n",
    "def new_dihedral(p0, p1, p2, p3):\n",
    "    \"\"\"Praxeolitic formula\n",
    "    1 sqrt, 1 cross product\n",
    "    \n",
    "    copied from \n",
    "    https://stackoverflow.com/questions/20305272/\n",
    "    dihedral-torsion-angle-from-four-points-in-cartesian-coordinates-in-python\"\"\"\n",
    "\n",
    "    b0 = -1.0*(p1 - p0)\n",
    "    b1 = p2 - p1\n",
    "    b2 = p3 - p2\n",
    "\n",
    "    # normalize b1 so that it does not influence magnitude of vector\n",
    "    # rejections that come next\n",
    "    b1 /= np.linalg.norm(b1)\n",
    "\n",
    "    # vector rejections\n",
    "    # v = projection of b0 onto plane perpendicular to b1\n",
    "    #   = b0 minus component that aligns with b1\n",
    "    # w = projection of b2 onto plane perpendicular to b1\n",
    "    #   = b2 minus component that aligns with b1\n",
    "    v = b0 - np.dot(b0, b1)*b1\n",
    "    w = b2 - np.dot(b2, b1)*b1\n",
    "\n",
    "    # angle between v and w in a plane is the torsion angle\n",
    "    # v and w may not be normalized but that's fine since tan is y/x\n",
    "    x = np.dot(v, w)\n",
    "    y = np.dot(np.cross(b1, v), w)\n",
    "    #return np.degrees(np.arctan2(y, x))\n",
    "    return np.arctan2(y, x)\n",
    "\n",
    "def calc_angles(coords):\n",
    "    '''\n",
    "    Basically loops over the coordinates and calculates the dihedral angles.\n",
    "    There should be ways to do this with vectorized computations but I don't know how.\n",
    "    '''\n",
    "    N = coords.shape[1]\n",
    "    angles_all = []\n",
    "    for i in range(0, N-3, 3):\n",
    "        psi = new_dihedral(*[coords[:, x] for x in range(i, i+4)])\n",
    "        omega = new_dihedral(*[coords[:, x] for x in range(i+1, i+5)])\n",
    "        phi = new_dihedral(*[coords[:, x] for x in range(i+2, i+6)])\n",
    "        angles = [psi, omega, phi]\n",
    "        angles_all.append(angles)\n",
    "    return(np.array(angles_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load some proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proteins = read_proteinnet_file('/Users/Deathvoodoo/big_folders_docs/data/casp7/training_70', 10000, verbose=False)\n",
    "val_proteins = read_proteinnet_file('/Users/Deathvoodoo/big_folders_docs/data/casp7/validation', 1000, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function below to transform the sequences and coordinates into one-hot encoding and dihedral angles. The easiest thing to do would be to pad everything to the length of the longest protein and put it in one tensor, but this has consequences for the output of the network later (nonzero outputs at places that should be zero).\n",
    "<br>\n",
    "<br>\n",
    "Note that since I don't have access to powerful compute resources I'm only running with a small number of proteins for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onehot_angles(protein_dict, pad, max_length=1500):\n",
    "    \"\"\"\n",
    "    Get onehot sequence and calculate angles from 3d coords for the protein dictionary.\n",
    "    Sometimes the angle calculation will produce nans, we remove those sequences.\n",
    "    If pad==True we will numbers as tensors, otherwise lists, along with remaining ids.\n",
    "    \"\"\"\n",
    "    remaining_ids = list(protein_dict.keys())\n",
    "    sequence_list = []\n",
    "    angle_list = []\n",
    "    for key in protein_dict.keys():\n",
    "        sequence = aa_to_onehot(protein_dict[key]['primary'], aa_id_dict, protein_dict[key]['mask'])\n",
    "        coords = protein_dict[key]['tertiary']\n",
    "        angles = calc_angles(coords).T\n",
    "        if pad:\n",
    "            if max_length-sequence.shape[0] < 0:\n",
    "                print(key, ' exceeds max length: ', max_length, ' , skipping...')\n",
    "                continue\n",
    "            else:\n",
    "                # pad the width, current shape is C*W\n",
    "                sequence_padded = np.pad(\n",
    "                    sequence, pad_width = ((0,0), (0, max_length-sequence.shape[1])), \n",
    "                    constant_values = 0)\n",
    "                sequence_list.append(sequence_padded)\n",
    "                angles_padded = np.pad(\n",
    "                    angles, pad_width = ((0,0), (0, max_length-sequence.shape[1])),\n",
    "                    constant_values = 0)\n",
    "                angle_list.append(angles_padded)\n",
    "        else: \n",
    "            angle_list.append(angles)\n",
    "            sequence_list.append(sequence)\n",
    "    N = len(sequence_list)\n",
    "    have_nans = []\n",
    "    for i,j in enumerate(angle_list):\n",
    "        if np.isnan(j).any():\n",
    "            have_nans.append(i)\n",
    "    inds_to_keep = np.arange(N)[np.logical_not(np.isin(np.arange(N), have_nans))].tolist()\n",
    "    \n",
    "    sequence_list = [sequence_list[i] for i in inds_to_keep]\n",
    "    angle_list = [angle_list[i] for i in inds_to_keep]\n",
    "    remaining_ids = [remaining_ids[i] for i in inds_to_keep]\n",
    "    coord_list = [protein_dict[rem_id]['tertiary'] for rem_id in remaining_ids]\n",
    "    if pad:\n",
    "        sequence_tensor = torch.tensor(sequence_list).float()\n",
    "        sequence_tensor = sequence_tensor #.unsqueeze(1)\n",
    "        angle_tensor = torch.tensor(angle_list).float()\n",
    "        angle_tensor = angle_tensor #.unsqueeze(1)\n",
    "        return([sequence_tensor, angle_tensor, remaining_ids])\n",
    "    else:\n",
    "        for i in range(len(sequence_list)):\n",
    "            ith_seq = (torch.tensor(sequence_list[i]).float()).unsqueeze(0)\n",
    "            sequence_list[i] = ith_seq #.unsqueeze(0)\n",
    "            ith_angles = (torch.tensor(angle_list[i]).float()).unsqueeze(0)\n",
    "            angle_list[i] = ith_angles #.unsqueeze(0)\n",
    "        return([sequence_list, coord_list, angle_list, remaining_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:44: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "train_seqs, train_coords, train_angles, train_ids_remain = get_onehot_angles(train_proteins, pad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:44: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "val_seqs, val_coords, val_angles, val_ids_remain = get_onehot_angles(val_proteins, pad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also calculate sin and cos to transform the angles into better values for the squared loss error function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sin_cos(array, as_torch_tensor=True):\n",
    "    sin = np.sin(array)\n",
    "    cos = np.cos(array)\n",
    "    sin_cos = np.concatenate([sin, cos], axis=1)\n",
    "    if as_torch_tensor:\n",
    "        sin_cos = torch.tensor(sin_cos)\n",
    "    return(sin_cos)\n",
    "\n",
    "def back_to_angle(sin_cos_array, n_angles=3):\n",
    "    angles = []\n",
    "    for i in range(n_angles):\n",
    "        angles_i = np.arctan2(sin_cos_array[:, i, :], sin_cos_array[:, n_angles+i, :])\n",
    "        # remember that we input sin first due to atan2 definition\n",
    "        angles_i = angles_i[:, np.newaxis, :]\n",
    "        angles.append(angles_i)\n",
    "    angles_arr = np.concatenate(angles, 1)\n",
    "    return(angles_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_angles_sin_cos = [get_sin_cos(i) for i in train_angles]\n",
    "val_angles_sin_cos = [get_sin_cos(i) for i in val_angles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the proteins and transforming the coords to angles etc. takes forever, so we just load some of them and then pickle them for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "train_data_proc = {'train_seqs':train_seqs, 'train_coords':train_coords,\n",
    "                   'train_angles_sin_cos': train_angles_sin_cos, 'train_ids_after_filt':train_ids_remain}\n",
    "\n",
    "val_data_proc = {'val_seqs':val_seqs, 'val_coords':val_coords,\n",
    "                   'val_angles_sin_cos': val_angles_sin_cos, 'val_ids_after_filt':val_ids_remain}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = open('protein_fcn_data_test/train_data_proc', 'wb')\n",
    "pickle.dump(train_data_proc, train_file)\n",
    "train_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_file = open('protein_fcn_data_test/val_data_proc', 'wb')\n",
    "pickle.dump(val_data_proc, val_file)\n",
    "val_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf = open('protein_fcn_data_test/val_data_proc', 'rb')\n",
    "test = pickle.load(asdf)\n",
    "asdf.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
